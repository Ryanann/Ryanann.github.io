<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Transformers包 - 
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
 
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site: ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="https://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; </span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
        
        <li><a target="_self" href="index.html">Home</a></li>
        
        <li><a target="_self" href="archives.html">Archives</a></li>
        

    <li><label>Categories</label></li>

        
            <li><a href="vim.html">vim</a></li>
        
            <li><a href="code.html">code</a></li>
        
            <li><a href="thoughts.html">thoughts</a></li>
        
            <li><a href="java.html">java</a></li>
        
            <li><a href="machine%20learning.html">machine learning</a></li>
        
            <li><a href="network.html">network</a></li>
        
            <li><a href="code%20race.html">code race</a></li>
        
            <li><a href="database.html">database</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>Transformers包</h1>
     
        <div class="read-more clearfix">
          <span class="date">2023/8/19</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='machine%20learning.html'>machine learning</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <p><img src="media/16924532520149/16930222139568.jpg" alt="" /></p>
<p>Transformers 是 huggingface 推出的 NLP python 库。兼容 pytorch, tensorflow 等框架，提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。它的宗旨是让最先进的 NLP 技术人人易用，从下面的例子可以看出确实简洁易用。</p>
<h2><a id="%E4%BD%BF%E7%94%A8%E6%A0%B7%E4%BE%8B" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>使用样例</h2>
<pre><code class="language-plain_text">from transformers import pipeline

# 情感分析
classifier = pipeline('sentiment-analysis')
classifier('We love AI a lot')

#&gt;&gt;&gt; output: [{'label': 'POSITIVE', 'score': 0.9996680428695679}]
</code></pre>
<p>三行代码就调用了开源模型并且完成了情感分析。第二行代码下载并缓存了预训练模型，第三行代码则在给定的文本上进行了评估。</p>
<pre><code class="language-plain_text">from transformers import AutoTokenizer
import transformers
import torch

tokenizer = AutoTokenizer.from_pretrained('model_file/Llama-2-7b-chat-hf')
pipeline = transformers.pipeline(
    &quot;text-generation&quot;, # 任务类型
    model=model_path,
    torch_dtype=torch.float16, # 参数精度
    device_map=&quot;auto&quot;, # 参数将模型的计算设备名(如cuda:0)映射到GPU上
)

answer = pipeline(
    'write a poem in praise of life',
    do_sample=True, 
    top_k=10,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    max_length=200
)

</code></pre>
<p>这是一个调用本地pytorch模型进行问题回答的case，同样十分简洁。本文余下部分主要对上述case中的一些参数进行介绍。</p>
<h2><a id="%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>模型文件</h2>
<p><strong>safetensors</strong><br />
huggingface 推出的一种安全快速的模型存储格式。transformer 加载本地包时优先分析文件夹中是否有 <code>model.safetensors.index.json</code> 文件，若有则按照 safetensors 格式加载模型，否则查看是否有其他格式的模型文件。</p>
<ul>
<li>safetensors: <a href="https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors">https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors</a></li>
</ul>
<p>此外模型文件中的 <code>config.json</code>文件记录了模型的一些主要信息，样例如下</p>
<pre><code class="language-plain_text">{
  &quot;_name_or_path&quot;: &quot;meta-llama/Llama-2-7b-chat-hf&quot;,
  &quot;architectures&quot;: [
    &quot;LlamaForCausalLM&quot;
  ],
  &quot;bos_token_id&quot;: 1,
  &quot;eos_token_id&quot;: 2,
  &quot;hidden_act&quot;: &quot;silu&quot;,
  &quot;hidden_size&quot;: 4096,
  &quot;initializer_range&quot;: 0.02,
  &quot;intermediate_size&quot;: 11008,
  &quot;max_position_embeddings&quot;: 4096,
  &quot;model_type&quot;: &quot;llama&quot;,
  &quot;num_attention_heads&quot;: 32,
  &quot;num_hidden_layers&quot;: 32,
  &quot;num_key_value_heads&quot;: 32,
  &quot;pretraining_tp&quot;: 1,
  &quot;rms_norm_eps&quot;: 1e-06,
  &quot;rope_scaling&quot;: null,
  &quot;tie_word_embeddings&quot;: false,
  &quot;torch_dtype&quot;: &quot;float16&quot;,
  &quot;transformers_version&quot;: &quot;4.32.0.dev0&quot;,
  &quot;use_cache&quot;: true,
  &quot;vocab_size&quot;: 32000
}
</code></pre>
<h2><a id="tokenizer%E5%8A%A0%E8%BD%BD" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>tokenizer加载</h2>
<p>tokenizer 的选择也同样通过模型文件中的配置文件来确定。具体地，会读取 <code>tokenizer_config.json</code> 文件并根据其中 <code>tokenizer_class</code> 字段的值选取相应类。</p>
<pre><code class="language-plain_text">{
  &quot;add_bos_token&quot;: true,
  &quot;add_eos_token&quot;: false,
  &quot;bos_token&quot;: {
    &quot;__type&quot;: &quot;AddedToken&quot;,
    &quot;content&quot;: &quot;&lt;s&gt;&quot;,
    &quot;lstrip&quot;: false,
    &quot;normalized&quot;: false,
    &quot;rstrip&quot;: false,
    &quot;single_word&quot;: false
  },
  &quot;clean_up_tokenization_spaces&quot;: false,
  &quot;eos_token&quot;: {
    &quot;__type&quot;: &quot;AddedToken&quot;,
    &quot;content&quot;: &quot;&lt;/s&gt;&quot;,
    &quot;lstrip&quot;: false,
    &quot;normalized&quot;: false,
    &quot;rstrip&quot;: false,
    &quot;single_word&quot;: false
  },
  &quot;legacy&quot;: false,
  &quot;model_max_length&quot;: 1000000000000000019884624838656,
  &quot;pad_token&quot;: null,
  &quot;padding_side&quot;: &quot;right&quot;,
  &quot;sp_model_kwargs&quot;: {},
  &quot;tokenizer_class&quot;: &quot;LlamaTokenizer&quot;,
  &quot;unk_token&quot;: {
    &quot;__type&quot;: &quot;AddedToken&quot;,
    &quot;content&quot;: &quot;&lt;unk&gt;&quot;,
    &quot;lstrip&quot;: false,
    &quot;normalized&quot;: false,
    &quot;rstrip&quot;: false,
    &quot;single_word&quot;: false
  }
}
</code></pre>
<h2><a id="%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%E5%92%8C%E6%8E%A8%E7%90%86" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>模型加载和推理</h2>
<p><strong>pipeline</strong><br />
Transformers 库最基础的对象就是 pipeline() 函数，它封装了预训练模型和对应的前处理和后处理环节。我们只需输入文本，就能得到预期的答案。目前常用的 pipelines 有：</p>
<ul>
<li>feature-extraction （获得文本的向量化表示）</li>
<li>fill-mask （填充被遮盖的词、片段）</li>
<li>ner（命名实体识别）</li>
<li>question-answering （自动问答）</li>
<li>sentiment-analysis （情感分析）</li>
<li>summarization （自动摘要）</li>
<li>text-generation （文本生成）</li>
<li>translation （机器翻译）</li>
<li>zero-shot-classification （零训练样本分类）</li>
</ul>
<p>pipelie 封装了许多操作，在上面列举的 case 中 pipeline 主要做了三个步骤(具体可参考&gt;&gt;&gt;<a href="https://transformers.run/intro/2021-12-08-transformers-note-1/#%25E8%25BF%2599%25E4%25BA%259B-pipeline-%25E8%2583%258C%25E5%2590%258E%25E5%2581%259A%25E4%25BA%2586%25E4%25BB%2580%25E4%25B9%2588">tutorial</a>)：</p>
<ol>
<li>预处理 (preprocessing)，将原始文本转换为模型可以接受的输入格式；</li>
<li>将处理好的输入送入模型；</li>
<li>对模型的输出进行后处理 (postprocessing)，将其转换为人类方便阅读的格式。<br />
<img src="media/16924532520149/16930264954724.jpg" alt="" /></li>
</ol>
<p><strong>参数精度</strong><br />
关于模型加载和推理的另外一个研究热点是参数精度。使用pipeline加载模型时我们通过<code>torch_dtype</code>参数指定精度，其实模型文件中也有同样的字段标注模型的精度情况。正常情况下 <code>torch_dtype=torch.float32</code>的模型也可以使用<code>torch_dtype=torch.float16</code>进行加载，以此节省GPU内存占用。</p>
<p>除此之外也有专门的研究工作探索在不改变推理效果的情况下尽量减少模型占用的内存。例如通过量化技术使用int8甚至更低的精度来加在模型。<br />
简单来说，量化技术使用线性或者非线性的方法把模型参数由<code>float16</code>范围映射到[-128, 127]或者更小的范围，在推理过程中再通过逆操作得到目标结果。</p>
<ul>
<li>LLM.int8量化：huggingface联合研究并深度集成的量化方案，无需额外训练过程，支持使用int8加载模型（参考文档&gt;&gt;&gt;<a href="https://arxiv.org/abs/2208.07339">1</a>, <a href="https://huggingface.co/blog/zh/hf-bitsandbytes-integration">2</a>, <a href="https://zhuanlan.zhihu.com/p/645308698">3</a>）</li>
<li>GPTQ量化：需要数据和训练过程来完成量化，支持int4精度加载模型，当前已有针对LLAMA的量化模型 （参考文档&gt;&gt;&gt;<a href="https://arxiv.org/abs/2210.17323">1</a>, <a href="https://towardsdatascience.com/4-bit-quantization-with-gptq-36b0f4f02c34">2</a>, <a href="https://github.com/qwopqwop200/GPTQ-for-LLaMa">3</a>）</li>
</ul>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="16447339815718.html" 
          title="Next Post: Build System">Build System &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="asset/img/photo.jpg" /></div>
            
                <h1></h1>
                <div class="site-des"></div>
                <div class="social">










<a target="_blank" class="email" href="mailto:669279048@qq.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="vim.html"><strong>vim</strong></a>
        
            <a href="code.html"><strong>code</strong></a>
        
            <a href="thoughts.html"><strong>thoughts</strong></a>
        
            <a href="java.html"><strong>java</strong></a>
        
            <a href="machine%20learning.html"><strong>machine learning</strong></a>
        
            <a href="network.html"><strong>network</strong></a>
        
            <a href="code%20race.html"><strong>code race</strong></a>
        
            <a href="database.html"><strong>database</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="16924532520149.html">Transformers包</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16447339815718.html">Build System</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="16445813243669.html">PU Learning (Learning from Positive and Unlabeled Example)</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15938652486267.html">Vim开发环境搭建</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="15848628637136.html">阿里云深度学习环境搭建</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>



  













<script src="asset/prism.js"></script>


<style type="text/css">
figure{margin: 0;padding: 0;}
figcaption{text-align:center;}

/* PrismJS 1.14.0
 http://prismjs.com/download.html#themes=prism&languages=markup+css+clike+javascript */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
    color: black;
    background: none;
    text-shadow: 0 1px white;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
    
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
    
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
    text-shadow: none;
    background:#b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
    text-shadow: none;
    background: #b3d4fc;
}

@media print {
    code[class*="language-"],
    pre[class*="language-"] {
        text-shadow: none;
    }
}

/* Code blocks */
pre[class*="language-"] {
    padding: 1em;
    margin: .5em 0;
    overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
    background: #F7F7F7;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
    padding: .1em;
    border-radius: .3em;
    white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
    color: slategray;
}

.token.punctuation {
    color: #999;
}

.namespace {
    opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
    color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
    color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
    color: #9a6e3a;
    background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
    color: #07a;
}

.token.function,
.token.class-name {
    color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
    color: #e90;
}

.token.important,
.token.bold {
    font-weight: bold;
}
.token.italic {
    font-style: italic;
}

.token.entity {
    cursor: help;
}


pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }

</style>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>



  </body>
</html>
